# Лабораторная работа №5

## 1. С использованием техники обучения Transfer Learning, оптимальной политики изменения темпа обучения, аугментации данных с оптимальными настройками обучить нейронную сеть EfficientNet-B0 (предварительно обученную на базе изображений imagenet) для решения задачи классификации изображений Food-101

## Используемые техники аугментации данных:
- Случайное горизонтальное отражение (mode - "horizontal")
- Поворот изображения на случайный угол со множителем угла равным 0.05
- Использование случайной части изображения с начальным размером изображения 250 * 250

### Графики обучения:
- Синяя линия - валидация
- Оранжевая линия - обучение

*График точности*
![Alt-текст](https://github.com/the-GriS/CNN-food-101/blob/lab_5/diagrams/lab_5/categorical_accuracy_all_aug.svg)

*График потерь*
![Alt-текст](https://github.com/the-GriS/CNN-food-101/blob/lab_5/diagrams/lab_5/loss_all_aug.svg)

## 2. С использованием техники обучения Fine Tuning дополнительно обучить нейронную сеть EfficientNet-B0 предварительно обученную в пункте 1

- Темп обучения на стадии Fine Tuning - 1e-7

### Графики для валидации:
- Синяя линия - запуск Fine Tuning после 10 эпох обучения первого эксперимента (до достижения максимальной точности на валидации)
- Оранжевая линия - запуск Fine Tuning после 18 эпох обучения первого эксперимента (сразу после достижения максимальной точности на валидации)
- Красная - запуск Fine Tuning после 25 эпох обучения первого эксперимента (спустя несколько эпох после достижения максимальной точности на валидации)

*График точности при валидации*
![Alt-текст](https://github.com/the-GriS/CNN-food-101/blob/lab_5/diagrams/lab_5/categorical_accuracy_fine.svg)

*График потерь при валидации*
![Alt-текст](https://github.com/the-GriS/CNN-food-101/blob/lab_5/diagrams/lab_5/loss_fine.svg)

## Анализ результатов  
В первом эксперименте максимальная точность на валидации (67.87% при потерях 1.195) была получена на 18 эпохе обучения. 

Использование техники обучения Fine Tuning улучшило нашу точность во всех трех случаях:
- при запуске Fine Tuning после 10 эпох обучения первого эксперимента мы получили максимальную точность равную 68.62% при потерях 1.196 после 14 эпох обучения Fine Tuning
- при запуске Fine Tuning после 18 эпох обучения первого эксперимента мы получили максимальную точность равную 69.38% при потерях 1.205 после 15 эпох обучения Fine Tuning
- при запуске Fine Tuning после 25 эпох обучения первого эксперимента мы получили максимальную точность равную 69.05% при потерях 1.223 после 12 эпох обучения Fine Tuning 
 
Таким образом можно сделать вывод, что использование техники обучения Fine Tuning оптимально сразу после достижения максимальной точности, это привело к улучшению результата на 1.51%. 
